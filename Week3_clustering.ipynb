{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random # library for random number generation\n",
    "import numpy as np # library for vectorized computation\n",
    "import pandas as pd # library to process data as dataframes\n",
    "\n",
    "import matplotlib.pyplot as plt # plotting library\n",
    "# backend for rendering plots within the browser\n",
    "%matplotlib inline \n",
    "\n",
    "from sklearn.cluster import KMeans \n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-MEANS ON A RANDOMly GENERATED DATASET\n",
    "\n",
    "# 30 data points belonging to 2 different clusters # data\n",
    "x1 = [-4.9, -3.5, 0, -4.5, -3, -1, -1.2, -4.5, -1.5, -4.5, -1, -2, -2.5, -2, -1.5, 4, 1.8, 2, 2.5, 3, 4, 2.25, 1, 0, 1, 2.5, 5, 2.8, 2, 2]\n",
    "x2 = [-3.5, -4, -3.5, -3, -2.9, -3, -2.6, -2.1, 0, -0.5, -0.8, -0.8, -1.5, -1.75, -1.75, 0, 0.8, 0.9, 1, 1, 1, 1.75, 2, 2.5, 2.5, 2.5, 2.5, 3, 6, 6.5]\n",
    "\n",
    "print('Datapoints defined!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that assigns each datapoint to a cluster\n",
    "colors_map = np.array(['b', 'r'])\n",
    "def assign_members(x1,x2,centers):\n",
    "    #distance\n",
    "    compare_to_first_center = np.sqrt(np.square(np.array(x1) - centers[0][0]) + np.square(np.array(x2) - centers[0][1]))\n",
    "    compare_to_second_center = np.sqrt(np.square(np.array(x1) - centers[1][0]) + np.square(np.array(x2) - centers[1][1]))\n",
    "    class_of_points = compare_to_first_center > compare_to_second_center #true or false\n",
    "    colors = colors_map[class_of_points + 1 - 1] #if true 1+1-1 if false 0+1-1\n",
    "    \n",
    "    return colors, class_of_points\n",
    "\n",
    "print('assign_members function defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that updates the centeroid of each cluster\n",
    "\n",
    "## update means\n",
    "def update_centers(x1,x2,class_of_points):\n",
    "    center1=[np.mean(np.array(x1)[~class_of_points]), np.mean(np.array(x2)[~class_of_points])] # cluster1 mean\n",
    "    center2=[np.mean(np.array(x1)[class_of_points]), np.mean(np.array(x2)[class_of_points])]   # cluster2 mean\n",
    "    \n",
    "    return [center1,center2]\n",
    "\n",
    "print('assign_members function defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that plots the data points along with the cluster centroids\n",
    "\n",
    "def plot_points(centroids=None,colors = 'g', figure_title=None):\n",
    "    #plot the figure\n",
    "    fig = plt.figure(figsize=(15,10)) # create a figure object\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    \n",
    "    centroid_colors = ['bx','rx']\n",
    "    if centroids:\n",
    "        for (i,centroid) in enumerate(centroids):\n",
    "            ax.plot(centroid[0], centroid[1],centroid_colors[i], markeredgewidth=5, markersize=20)\n",
    "    plt.scatter(x1,x2, s=500, c=colors)\n",
    "    \n",
    "    # define the ticks\n",
    "    xticks = np.linspace(-6, 8, 15, endpoint=True)\n",
    "    yticks = np.linspace(-6,6,13, endpoint=True)\n",
    "    \n",
    "    # fix the horizontal axis\n",
    "    ax.set_xticks(xticks)\n",
    "    ax.set_yticks(yticks)\n",
    "    \n",
    "    # add tick labels\n",
    "    xlabels = xticks\n",
    "    ax.set_xticklabels(xlabels)\n",
    "    ylabels = yticks\n",
    "    ax.set_yticklabels(ylabels)\n",
    "    \n",
    "    # style the ticks\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.tick_params('both',length=2,width=1,which='major',labelsize=15)\n",
    "    \n",
    "    # add labels to axes\n",
    "    ax.set_xlabel('x1', fontsize=20)\n",
    "    ax.set_ylabel('x2', fontsize=20)\n",
    "    \n",
    "    #add title to figure\n",
    "    ax.set_title(figure_title,fontsize=24)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "print('plot_points function defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize k-means - plot data points\n",
    "plot_points(figure_title='Scatter Plot of x2 vs x1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize k-means - randomly define clusters and add them to plot\n",
    "\n",
    "centers = [[-2,2],[2,-2]]\n",
    "plot_points(centers,figure_title='K-means Initialization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run k-means (4-iterations only)\n",
    "\n",
    "number_of_iterations = 4\n",
    "\n",
    "for i in range(number_of_iterations):\n",
    "    input('Iteration {} - Press Enter to update the members of each cluster'.format(i + 1))\n",
    "    colors, class_of_points = assign_members(x1,x2,centers)\n",
    "    title='Iteration {} - Cluster Assignment'.format(i+1)\n",
    "    plot_points(centers, colors,figure_title=title)\n",
    "    input('Iteration {} - Press Enter to update the centers'.format(i+1))\n",
    "    centers=update_centers(x1,x2,class_of_points)\n",
    "    title = 'Iteration {} - Centroid Update'.format(i+1)\n",
    "    plot_points(centers, colors,figure_title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Now we will use random to generate thousands of datapoints\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generating the Data\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Next we will be making *random clusters* of points by using the **make_blobs** class. The **make_blobs** class can take in many inputs, but we will use these specific ones.\n",
    "\n",
    "#     Input\n",
    "\n",
    "#     n_samples: The total number of points equally divided among clusters. \n",
    "#         Value will be: 5000\n",
    "#     centers: The number of centers to generate, or the fixed center locations. \n",
    "#         Value will be: [[4, 4], [-2, -1], [2, -3],[1,1]] \n",
    "#     cluster_std: The standard deviation of the clusters. \n",
    "#         Value will be: 0.9\n",
    "\n",
    "\n",
    "# Output\n",
    "\n",
    "#     X: Array of shape [n_samples, n_features]. (Feature Matrix)\n",
    "#         The generated samples.\n",
    "#     Y: Array of shape [n_samples]. (Response Vector)\n",
    "#         The integer labels for cluster membership of each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = make_blobs(n_samples=5000, centers=[[4, 4], [-2, -1], [2, -3], [1, 1]], cluster_std=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.scatter(X[:,0],X[:,1],marker='.') # [:,0] [:,1] taking all the rows but keep 0, keep 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting up k-means\n",
    "\n",
    "# The KMeans class has many parameters that can be used, but we will use these three:\n",
    "\n",
    "#     init: Initialization method of the centroids.\n",
    "#         Value will be: \"k-means++\". k-means++ selects initial cluster centers for k-means \n",
    "#                         clustering in a smart way to speed up convergence.\n",
    "# -----------------------------------------------------------------------------------------------------\n",
    "#     n_clusters: The number of clusters to form as well as the number of centroids to generate.\n",
    "#         Value will be: 4 (since we have 4 centers)\n",
    "# -----------------------------------------------------------------------------------------------------\n",
    "#     n_init: Number of times the k-means algorithm will be run with different centroid seeds. \n",
    "#             The final results will be the best output of n_init consecutive runs in terms of inertia.\n",
    "#         Value will be: 12\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize KMeans with these parameters, where the output parameter is called k_means.\n",
    "k_means = KMeans(init=\"k-means++\", n_clusters=4,n_init=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's fit the KMeans model with the feature matrix we created above, X .\n",
    "k_means.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's grab the labels for each point in the model using KMeans .labels_ attribute and save it as k_means_labels.\n",
    "k_means_labels = k_means.labels_\n",
    "k_means_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will also get the coordinates of the cluster centers using KMeans .cluster_centers_ \n",
    "# and save it as k_means_cluster_centers.\n",
    "\n",
    "k_means_cluster_centers = k_means.cluster_centers_\n",
    "k_means_cluster_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the plot with the specified dimensions.\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "\n",
    "# colors uses a color map, which will produce an array of colors based on\n",
    "# the number of labels. We use set(k_means_labels) to get the\n",
    "# unique labels.\n",
    "colors = plt.cm.Spectral(np.linspace(0, 1, len(set(k_means_labels))))\n",
    "\n",
    "# create a plot\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "# loop through the data and plot the datapoints and centroids.\n",
    "# k will range from 0-3, which will match the number of clusters in the dataset.\n",
    "for k, col in zip(range(len([[4,4], [-2, -1], [2, -3], [1, 1]])), colors):\n",
    "\n",
    "    # create a list of all datapoints, where the datapoitns that are \n",
    "    # in the cluster (ex. cluster 0) are labeled as true, else they are\n",
    "    # labeled as false.\n",
    "    my_members = (k_means_labels == k)\n",
    "    \n",
    "    # define the centroid, or cluster center.\n",
    "    cluster_center = k_means_cluster_centers[k]\n",
    "    \n",
    "    # plot the datapoints with color col.\n",
    "    ax.plot(X[my_members, 0], X[my_members, 1], 'w', markerfacecolor=col, marker='.')\n",
    "    \n",
    "    # plot the centroids with specified color, but with a darker outline\n",
    "    ax.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor=col,  markeredgecolor='k', markersize=6)\n",
    "\n",
    "# title of the plot\n",
    "ax.set_title('KMeans')\n",
    "\n",
    "# remove x-axis ticks\n",
    "ax.set_xticks(())\n",
    "\n",
    "# remove y-axis ticks\n",
    "ax.set_yticks(())\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. Using k-means for Customer Segmentation\n",
    "# Imagine that you have a customer dataset, and you are interested in exploring the behavior of your customers using their historical data.\n",
    "\n",
    "# Customer segmentation is the practice of partitioning a customer base into groups of individuals that have similar characteristics.\n",
    "# It is a significant strategy as a business can target these specific groups of customers and effectively allocate marketing resources. \n",
    "# For example, one group might contain customers who are high-profit and low-risk, that is, more likely to purchase products, \n",
    "# or subscribe to a service. A business task is to retain those customers. Another group might include customers from non-profit organizations, and so on.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's download the data and save it as a CSV file called customer_segmentation.csv\n",
    "!wget -q -O 'customer_segmentation.csv' https://cocl.us/customer_dataset\n",
    "print('Data downloaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df = pd.read_csv('customer_segmentation.csv')\n",
    "customer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the categorical data\n",
    "df = customer_df.drop('Address',axis =1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now let's normalize the dataset. \n",
    "# But why do we need normalization in the first place? \n",
    "# Normalization is a statistical method that helps mathematical-based algorithms \n",
    "# interpret features with different magnitudes and distributions equally. \n",
    "# We use StandardScaler() to normalize our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "x = df.values[:,1:]\n",
    "x = np.nan_to_num(x)\n",
    "\n",
    "cluster_dataset = StandardScaler().fit_transform(x)\n",
    "cluster_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling\n",
    "\n",
    "num_clusters = 3\n",
    "\n",
    "k_means = KMeans(init=\"k-means++\",n_clusters=num_clusters, n_init=12)\n",
    "k_means.fit(cluster_dataset)\n",
    "labels = k_means.labels_\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insights\n",
    "df['Labels'] = labels\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Labels').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# k-means will partition your customers into three groups since we specified the algorithm to generate 3 clusters. \n",
    "# The customers in each cluster are similar to each other in terms of the features included in the dataset.\n",
    "\n",
    "# Now we can create a profile for each group, considering the common characteristics of each cluster. \n",
    "# For example, the 3 clusters can be:\n",
    "\n",
    "# OLDER, HIGH INCOME, AND INDEBTED\n",
    "# MIDDLE AGED, MIDDLE INCOME, AND FINANCIALLY RESPONSIBLE\n",
    "# YOUNG, LOW INCOME, AND INDEBTED\n",
    "# However, you can devise your own profiles based on the means above and come up with labels that you think best describe each cluster.\n",
    "\n",
    "# I hope that you are able to see the power of k-means here. \n",
    "# This clustering algorithm provided us with insight into the dataset and lead us to group the data into three clusters. \n",
    "# Perhaps the same results would have been achieved but using multiple tests and experiments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
